{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --force-reinstall numpy==1.26.4 scipy==1.13.1 datasets gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ClDnDxDmyj0U"
   },
   "source": [
    "### 1. Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the `datasets` library if it's not already installed\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "dataset = load_dataset(\"surrey-nlp/PLOD-CW-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gf_tXhY7Bpjr"
   },
   "source": [
    "##### Checking missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing(dataset_split):\n",
    "    missing_counts = {}\n",
    "    for feature in dataset_split.features:\n",
    "        count = sum(1 for example in dataset_split if example[feature] is None)\n",
    "        missing_counts[feature] = count\n",
    "    return missing_counts\n",
    "\n",
    "for split in dataset:\n",
    "    print(f\"\\nMissing values in {split}:\")\n",
    "    print(check_missing(dataset[split]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the total number of sentences in each split\n",
    "print(\"\\nNumber of Sentences in Each Split:\")\n",
    "for split in dataset.keys():\n",
    "    print(f\"{split.capitalize()} Split: {len(dataset[split])} sentences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6wmz6wu5B22G"
   },
   "source": [
    "##### Token and TAG Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Flatten all tokens from train split and convert to lowercase\n",
    "all_tokens = [token.lower() for example in dataset['train'] for token in example['tokens']]\n",
    "token_freq = Counter(all_tokens)\n",
    "top_tokens = token_freq.most_common(20)\n",
    "\n",
    "# Plot top 20 most frequent tokens\n",
    "words, freqs = zip(*top_tokens)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.bar(words, freqs)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Top 20 Frequent Tokens\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U94_sxf70mi2"
   },
   "source": [
    "Key insights:\n",
    "1. Punctuation (',', '(', ')', '.') and stopwords (\"the\", \"of\", \"and\") are the most frequent tokens.\n",
    "\n",
    "2. Biomedical terms or abbreviations are not visible in the top 20.\n",
    "\n",
    "3. Suggests that non-entity tokens dominate the dataset, highlighting the importance of focusing on labeled tokens for biomedical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "all_pos = [pos for sentence in dataset['train']['pos_tags'] for pos in sentence]\n",
    "pos_counts = Counter(all_pos)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(pos_counts.keys(), pos_counts.values())\n",
    "plt.title(\"POS Tag Distribution (Training Set)\")\n",
    "plt.xlabel(\"POS Tag\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2AxpX_ZP0ex0"
   },
   "source": [
    "Key insights:\n",
    "\n",
    "1. NOUN and PUNCT are the most frequent POS tags, followed by proper nouns (PROPN) and adjectives (ADJ).\n",
    "\n",
    "2. Indicates that biomedical terms likely appear as nouns or proper nouns, with heavy punctuation usage (typical of scientific text)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Flatten all NER tags from the training set\n",
    "all_ner_labels = [label for ex in dataset['train'] for label in ex['ner_tags']]\n",
    "\n",
    "# Count the frequency of each NER tag\n",
    "label_counts = Counter(all_ner_labels)\n",
    "\n",
    "# Plot the distribution\n",
    "plt.bar(label_counts.keys(), label_counts.values())\n",
    "plt.title(\"NER Label Distribution in Training Set\")\n",
    "plt.xlabel(\"NER Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tuo1xedY01PH"
   },
   "source": [
    "Key insights\n",
    "\n",
    "1. Majority of tokens are labeled as O (non-entity).\n",
    "\n",
    "2. Among labeled tokens, I-LF (inside long-form) is the most common, followed by B-AC (abbreviation) and B-LF (begin long-form).\n",
    "\n",
    "3. Shows class imbalance, with many more non-entity tokens than labeled entities — important for model training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NMyfjdD2VYsm"
   },
   "source": [
    "### 2. Word Frequency (excluding 'O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ADD THE GRAPH FOR WORD FREQUENCY IGNORING THE 'O' TAGS -> amir\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tokens = []\n",
    "\n",
    "for row in dataset['train']:\n",
    "  for token, tag in zip(row['tokens'], row['ner_tags']):\n",
    "    if tag != 'O' and len(token) > 1:\n",
    "      tokens.append(token)\n",
    "\n",
    "token_freq = Counter(tokens)\n",
    "top_tokens = token_freq.most_common(20)\n",
    "print(top_tokens)\n",
    "\n",
    "words, freqs = zip(*top_tokens)\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.bar(words, freqs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIg9sIwQ18of"
   },
   "source": [
    "Key insights:\n",
    "\n",
    "1.Generic words like “of”, “and”, and “the” still appear frequently even in labeled tokens, suggesting that some long-forms may contain common English words.\n",
    "\n",
    "2. Domain-specific terms such as “protein”, “cell”, “disease”, “ratio”, “receptor”, and “RNA” are among the top frequent labeled tokens, reflecting the biomedical nature of the dataset.\n",
    "\n",
    "3. Some abbreviations like “CI”, “WT”, and “RNA” appear, indicating that abbreviation labels (B-AC) are being captured in the top frequencies.\n",
    "\n",
    "4. The presence of common functional words in the labeled tokens highlights that biomedical entities often contain stopwords (e.g., \"confidence interval\", \"protein of interest\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbeG_bVv2dnV"
   },
   "source": [
    "### 3. Top Abbreviated Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: SHOW TOP ABBRIVIATED WORDS -> shivasmi\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "abbreviation_counts = Counter()\n",
    "\n",
    "# Working only on the train split\n",
    "for example in dataset[\"train\"]:\n",
    "    tokens = example['tokens']\n",
    "    tags = example['ner_tags']\n",
    "\n",
    "    for token, tag in zip(tokens, tags):\n",
    "        # Allow letters (A-Z, a-z), numbers (0-9), and hyphens (-), length > 1\n",
    "        if tag == \"B-AC\" and re.match(r\"^[A-Za-z0-9\\-]+$\", token) and len(token) > 1:\n",
    "            abbreviation_counts[token] += 1\n",
    "\n",
    "# Show Top 10 Abbreviated Words after filtering\n",
    "print(\"\\nTop Abbreviated Words:\")\n",
    "for abbr, count in abbreviation_counts.most_common(10):\n",
    "    print(f\"{abbr:<10} → {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 10 abbreviations and their counts\n",
    "top_abbr, top_counts = zip(*abbreviation_counts.most_common(10))\n",
    "\n",
    "# Plotting with better style\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(top_abbr, top_counts, color='#4c72b0', edgecolor='black', linewidth=1.2)\n",
    "\n",
    "# Add count labels on top of bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.annotate(f'{height}',\n",
    "                 xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                 xytext=(0, 5),  # Offset label position\n",
    "                 textcoords=\"offset points\",\n",
    "                 ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Customizing the plot\n",
    "plt.title(\"Top Abbreviated Words in Biomedical Text\", fontsize=16, fontweight='bold', color='#333333')\n",
    "plt.xlabel(\"Abbreviation\", fontsize=12, fontweight='bold')\n",
    "plt.ylabel(\"Frequency\", fontsize=12, fontweight='bold')\n",
    "plt.xticks(rotation=45, fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Remove top and right spines for a cleaner look\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60mnNXbU3PE3"
   },
   "source": [
    "Key insights:\n",
    "\n",
    "1. “CI” and “WT” are the most frequent abbreviations, followed by “HR”, “OR”, and “BMI”.\n",
    "\n",
    "2. Abbreviations reflect a mix of statistical terms (e.g., CI, HR, OR) and biomedical entities/diseases (e.g., GFP, TB, MS).\n",
    "\n",
    "  Indicates the need for domain-aware abbreviation handling in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CP2B_vGW3Xbj"
   },
   "source": [
    "### 4. Long-form & Abbreviation Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: LONG FORMAT AND SHORT FORMAT RELATION -> ishwari\n",
    "# examples where acronym (B-AC) appears\n",
    "for i in range(5):\n",
    "    tags = dataset['train'][i]['ner_tags']\n",
    "    if 'B-AC' in tags:\n",
    "        print(\"Tokens:\", dataset['train'][i]['tokens'])\n",
    "        print(\"NER Tags:\", tags)\n",
    "        print(\"---\")\n",
    "\n",
    "# Initializing counters\n",
    "with_both = 0\n",
    "only_acronym = 0\n",
    "only_longform = 0\n",
    "neither = 0\n",
    "\n",
    "# Going through each sentence in the training set\n",
    "for ex in dataset['train']:\n",
    "    tags = ex['ner_tags']\n",
    "\n",
    "    has_acronym = 'B-AC' in tags\n",
    "    has_longform = 'B-LF' in tags or 'I-LF' in tags\n",
    "\n",
    "    if has_acronym and has_longform:\n",
    "        with_both += 1\n",
    "    elif has_acronym:\n",
    "        only_acronym += 1\n",
    "    elif has_longform:\n",
    "        only_longform += 1\n",
    "    else:\n",
    "        neither += 1\n",
    "\n",
    "print(\"Sentences with BOTH acronym and long form:\", with_both)\n",
    "print(\"Sentences with ONLY acronym:\", only_acronym)\n",
    "print(\"Sentences with ONLY long form:\", only_longform)\n",
    "print(\"Sentences with NEITHER:\", neither)\n",
    "print('\\n')\n",
    "\n",
    "#Visualizing with Bar Chart\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = ['Both Short & Long', 'Only Short', 'Only Long', 'Neither']\n",
    "counts = [with_both, only_acronym, only_longform, neither]\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(labels, counts, color='cornflowerblue')\n",
    "plt.title(\"Co-occurrence of Acronyms (Short) and Long Forms\")\n",
    "plt.ylabel(\"Number of Sentences\")\n",
    "plt.xticks(rotation=15)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdwXc7Mh3t36"
   },
   "source": [
    "Key Insights:\n",
    "\n",
    "1. Most sentences (1986) contain both abbreviations and their corresponding long forms, indicating clear abbreviation–long-form pairings.\n",
    "\n",
    "2. Very few sentences have only abbreviations (2) or only long forms (12), showing that isolated occurrences are rare.\n",
    "\n",
    "3. No sentences are unlabeled (neither abbreviation nor long form), confirming the dataset is well-annotated.\n",
    "\n",
    "4. Highlights that sentence-level context is strong for abbreviation detection, as both forms often co-occur together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNIh-DLg4Fdx"
   },
   "source": [
    "### 5. Sentences with Only Abbreviations or Only Long-forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Sentences with Only Abbreviations or Only Long-forms -> ritwik\n",
    "\n",
    "print(\"\\nSentences with only abbreviation (B-AC, no B-LF):\\n\")\n",
    "count = 0\n",
    "for ex in dataset[\"train\"]:\n",
    "    tags = ex[\"ner_tags\"]\n",
    "    if \"B-AC\" in tags and \"B-LF\" not in tags:\n",
    "        print(\" \".join(ex[\"tokens\"]))\n",
    "        count += 1\n",
    "        if count >= 3:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IaLFrKti8ntP"
   },
   "source": [
    "Key Insight:\n",
    "1. Some short forms like CD5-2, TLR2, PD98059, eRNA, etc. are used without explaining their full forms in the same sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSentences with only long-form (B-LF, no B-AC):\\n\")\n",
    "count = 0\n",
    "for ex in dataset[\"train\"]:\n",
    "    tags = ex[\"ner_tags\"]\n",
    "    if \"B-LF\" in tags and \"B-AC\" not in tags:\n",
    "        print(\" \".join(ex[\"tokens\"]))\n",
    "        count += 1\n",
    "        if count >= 12:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2_Jmx_68rym"
   },
   "source": [
    "Key insights:\n",
    "\n",
    "1. Some technical terms like “chaperone protein DnaK” or “Plasmodium falciparum strain FCR3” are written fully without abbreviation.\n",
    "\n",
    "2. This happens when:\n",
    "\n",
    "  -The term is used only once.\n",
    "  -The term itself is already short or clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4foujBD5H2v"
   },
   "source": [
    "### 6. Abbreviation ↔ POS Tag Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: RELATION BETWEEN ABBRIVIATION AND POS TAG -> faye\n",
    "\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# initialise a dictionary to store abbreviation-POS pairs\n",
    "abbr_pos_counts = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# iterate through the dataset to find abbreviations and their POS tags\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    for example in dataset[split]:\n",
    "        tokens = example['tokens']\n",
    "        pos_tags = example['pos_tags']\n",
    "\n",
    "        for token, pos_tag in zip(tokens, pos_tags):\n",
    "            # check if the token is likely an abbreviation (heuristic: contains '.' or is uppercase)\n",
    "            if '.' in token or (token.isupper() and len(token) <= 5):\n",
    "                abbr_pos_counts[token][pos_tag] += 1\n",
    "\n",
    "# convert to a dataframe for analysis\n",
    "abbr_pos_df = pd.DataFrame([\n",
    "    (abbr, pos, count)\n",
    "    for abbr in abbr_pos_counts\n",
    "    for pos, count in abbr_pos_counts[abbr].items()\n",
    "], columns=['Abbreviation', 'POS_Tag', 'Count'])\n",
    "\n",
    "# display the top abbreviation POS pairs\n",
    "print(abbr_pos_df.sort_values('Count', ascending=False).head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate counts by POS tag\n",
    "pos_counts = abbr_pos_df.groupby('POS_Tag')['Count'].sum().reset_index()\n",
    "pos_counts = pos_counts.sort_values('Count', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=pos_counts, x='POS_Tag', y='Count', palette='viridis')\n",
    "plt.title('Most Common POS Tags for Abbreviations')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PFnBi2u9du7"
   },
   "source": [
    "Key insights:\n",
    "1. Most abbreviations are tagged as Proper Nouns (PROPN) and Nouns (NOUN), matching common biomedical entities like genes, proteins, and diseases.\n",
    "\n",
    "2. High PUNCT count suggests tokenization splits (e.g., hyphens in \"IL-2\") leading to punctuation being misclassified as abbreviations.\n",
    "\n",
    "3. Presence of NUM (numbers) reflects abbreviations with numeric components (e.g., S1, 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1h2CbcbS-H6S"
   },
   "source": [
    "### 7. Tag Transition Matrix (NER Transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Tag transition - Shivasmi\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def get_all_transitions(dataset_split):\n",
    "    transitions = Counter()\n",
    "    for example in dataset_split:\n",
    "        labels = example['ner_tags']\n",
    "        for i in range(len(labels) - 1):\n",
    "            transitions[(labels[i], labels[i + 1])] += 1\n",
    "    return transitions\n",
    "\n",
    "def transitions_to_dataframe(transitions):\n",
    "    data = []\n",
    "    for (prev_tag, next_tag), count in transitions.items():\n",
    "        data.append({\n",
    "            'Previous Tag': prev_tag,\n",
    "            'Next Tag': next_tag,\n",
    "            'Count': count\n",
    "        })\n",
    "    df = pd.DataFrame(data)\n",
    "    return df.sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Get transitions\n",
    "train_transitions = get_all_transitions(dataset['train'])\n",
    "\n",
    "# Convert to DataFrame (no id2label needed!)\n",
    "df_transitions = transitions_to_dataframe(train_transitions)\n",
    "print(df_transitions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare labels and counts\n",
    "labels = df_transitions.apply(lambda x: f\"{x['Previous Tag']} → {x['Next Tag']}\", axis=1)\n",
    "counts = df_transitions[\"Count\"]\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.bar(labels, counts)\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_xlabel(\"Tag Transition (Previous → Next)\")\n",
    "ax.set_title(\"Tag Transition Counts\")\n",
    "\n",
    "# Rotate x-axis labels for better visibility\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Remove grid\n",
    "ax.grid(False)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__fTCUGQ-St_"
   },
   "source": [
    "A. Rare transitions: Transition Count What it may indicate\n",
    "\n",
    "1. B-AC → B-LF 42; Abbreviation followed immediately by long form\n",
    "2. I-LF → B-AC 15; Ending long form → new abbreviation without 'O' token between\n",
    "3. I-LF → B-LF 5; One long form starts right after inside of another long form\n",
    "4. B-LF → B-AC 1; Very rare: long form followed by abbreviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FCqVA5l5-VfE"
   },
   "source": [
    "B. The majority of transitions are from\n",
    "\n",
    "1. O → O, reflecting a strong class imbalance toward non-entity tokens.\n",
    "2. Long forms typically span multiple tokens as shown by frequent B-LF → I-LF and I-LF → I-LF transitions.\n",
    "\n",
    "Rare transitions such as B-AC → B-LF suggest edge cases where abbreviations are directly followed by long forms, which may challenge sequence-based models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-QEVspm9j6b"
   },
   "source": [
    "### 8. Symbol and Token Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: SHOW THE SYMBOLS -> amir\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "uncommon_pattern = re.compile(r'[αβγδΔΓΩω]')\n",
    "tokens = []\n",
    "\n",
    "for row in dataset['train']:\n",
    "  for token, tag in zip(row['tokens'], row['ner_tags']):\n",
    "    if uncommon_pattern.search(token):\n",
    "      tokens.append(token)\n",
    "\n",
    "token_freq = Counter(tokens)\n",
    "top_tokens = token_freq.most_common(20)\n",
    "print(top_tokens)\n",
    "\n",
    "words, freqs = zip(*top_tokens)\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.bar(words, freqs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8L13XDJAJGN"
   },
   "source": [
    "Key insights:\n",
    "1. Greek letters like α (alpha), β (beta), γ (gamma) are the most frequently occurring symbols in biomedical terms.\n",
    "\n",
    "2. These symbols are often used in protein names, receptor types, or biological pathways (e.g., TGFβ, Aβ, PDGFRα).\n",
    "\n",
    "3. The presence of such symbols highlights the importance of correctly handling non-English characters during tokenization and abbreviation detection.\n",
    "\n",
    "4. Rare symbols like ω (omega), Δ (delta), and their combinations (e.g., Δm157, αSMA) also appear, often representing variants or specific subtypes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pzyWJDlejcLc"
   },
   "source": [
    "### 9. Abbreviation Ambiguity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Abbreviation amibiguity check - ritwik\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "abbr_map = defaultdict(set)\n",
    "\n",
    "for example in dataset['train']:\n",
    "    tokens = example['tokens']\n",
    "    tags = example['ner_tags']\n",
    "    current_abbr = None\n",
    "    current_lf = []\n",
    "\n",
    "    for token, tag in zip(tokens, tags):\n",
    "        if tag == 'B-AC':\n",
    "            current_abbr = token\n",
    "        elif tag == 'B-LF':\n",
    "            current_lf = [token]\n",
    "        elif tag == 'I-LF' and current_lf:\n",
    "            current_lf.append(token)\n",
    "        elif tag == 'O':\n",
    "            if current_abbr and current_lf:\n",
    "                abbr_map[current_abbr].add(\" \".join(current_lf))\n",
    "                current_abbr = None\n",
    "                current_lf = []\n",
    "\n",
    "# Count ambiguous abbreviations\n",
    "ambiguous_abbr = {abbr: lfs for abbr, lfs in abbr_map.items() if len(lfs) > 1}\n",
    "num_ambiguous = len(ambiguous_abbr)\n",
    "\n",
    "print(f\"\\n Total Ambiguous Abbreviations: {num_ambiguous}\")\n",
    "print(\"\\nSome Examples of Ambiguous Abbreviations:\")\n",
    "\n",
    "# Show abbreviations with more than one long form\n",
    "for abbr, lfs in list(ambiguous_abbr.items())[:10]:\n",
    "    if len(lfs) > 1:\n",
    "        print(f\"{abbr} → {lfs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aq73YDF3kDk4"
   },
   "source": [
    "Key insights:\n",
    "\n",
    "1. total of 437 ambiguous abbreviations were identified, meaning these abbreviations map to more than one possible long-form.\n",
    "\n",
    "2. Examples like:\n",
    "\n",
    "  -\"KD\" → knockdown, kinase - inactive mutant, equilibrium dissociation constant, etc.\n",
    "\n",
    "  -\"TLR\" → toll-like receptor, non-ulcer dyspepsia\n",
    "show how the same abbreviation can represent completely different biomedical terms.\n",
    "\n",
    "3. Some abbreviations like \"d\", \"HC\", and \"ND\" map to 5 or more long-forms, increasing the risk of confusion for models.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
